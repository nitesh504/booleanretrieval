# -*- coding: utf-8 -*-
"""boolean_retrieval.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oYw__xbPQRUXkF0bgzyYkbraXXC9NOop
"""

import nltk
import re
import os
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from collections import defaultdict, Counter

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

from google.colab import drive
drive.mount('/content/drive')

def read_documents(path):
    content = {}
    doc_id_filename = {}
    doc_id = 0
    for filename in os.listdir(path):
        if filename.endswith(".txt"):
            with open(os.path.join(path, filename), 'r', encoding='utf-8') as file:
                content[doc_id] = file.read()
                doc_id_filename[doc_id] = filename
                doc_id += 1
    return content, doc_id_filename

def text_cleaning(text):
    text = text.lower()
    text = re.sub(r'http[s]?://\S+', '', text)
    text = re.sub(r"[^a-zA-Z0-9\s]", "", text)

    tokens = word_tokenize(text)
    cleaned_text = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]
    return cleaned_text

def build_inverted_index(document):
    index = defaultdict(set)
    frequency = Counter()
    for doc_id, content in document.items():
        cleaned_tokens = text_cleaning(content)
        for token in cleaned_tokens:
            index[token].add(doc_id)
            frequency[token] += 1
    return index, frequency

def parse_query(query):
    query = query.lower()
    tokens = re.split(r'(\sand\s|\sor\s|\snot\s)', query)
    tokens = [token.strip() for token in tokens if token.strip()]
    return tokens

def boolean_retrieval(query, inverted_index, doc_id_filename):
    tokens = parse_query(query)
    if not tokens:
        return []

    result_set = set()
    operator = None

    for token in tokens:
        if token in {"and", "or", "not"}:
            operator = token
        else:
            current_set = inverted_index.get(token, set())
            if operator == "and":
                result_set &= current_set
            elif operator == "or":
                result_set |= current_set
            elif operator == "not":
                result_set -= current_set
            else:
                result_set = current_set

    result_filenames = [doc_id_filename[doc_id] for doc_id in result_set]
    return result_filenames

def main():

    path = '/content/drive/MyDrive/documents'
    content, doc_id_filenames = read_documents(path)
    inverted_index, frequency = build_inverted_index(content)

    sorted_inverted_index = dict(sorted(inverted_index.items()))


    queries = [
        "UNESCO",
        "currency AND capital",
        "Great Wall",
        "Taj Mahal AND UNESCO",
        "Colosseum NOT France"
    ]


    for query in queries:
        result = boolean_retrieval(query, sorted_inverted_index, doc_id_filenames)
        final_result = f'Query: {query}, Result: {result}'
        print(final_result)

if __name__ == "__main__":
    main()